# -*- coding: utf-8 -*-
"""Guass_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aT272shkJ-rk6EzcXwPiNujpQxeGln_x
"""

!nvidia-smi

import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"
tf.__version__

"""#Part 1: Data Preprocessing

##Image Data Augmentation with ImageDataGenerator
**ImageDataGenerator** in Keras is a powerful utility that allows for the preprocessing and real-time augmentation of image data. This tool is essential for enhancing the diversity of the dataset without physically expanding it, thereby helping in the development of robust machine learning models. Below, we describe the transformations applied to both training and testing datasets:

1.   Training Data Transformations


- Rescaling (Normalization):

 * Purpose: Converts pixel values from a range of [0, 255] to [0, 1], ensuring that the neural network processes inputs that are normalized, leading to more stable and faster convergence.
  * Computer Vision Concept: This is a basic form of data scaling in image processing, critical for balancing input feature scales.

- Shear Transformation:

  * Purpose: Randomly distorts the image along an axis, typically simulating a tilt, which helps the model learn to recognize objects in images that are not perfectly aligned with the axis.
  * Computer Vision Concept: Shear is a type of affine transformation that slants the shape of an image, preserving lines but not distances or angles.

- Zoom Transformation:

  * Purpose: Randomly increases or decreases the size of the image, mimicking the effect of the camera moving closer or farther away. This teaches the model to recognize objects across different scales.
  * Computer Vision Concept: Zoom is a scaling transformation that changes the effective resolution of the imaged objects.

- Horizontal Flip:

  * Purpose: Mirrors the image along the vertical axis, effectively doubling the number of different orientations the model sees during training.
  * Computer Vision Concept: This is a reflection transformation, useful for datasets where object orientation is not a factor in classification accuracy.

2.   Testing Data Transformations
- Rescaling (Normalization):
  * Purpose and Concept: Identical to the training data, ensures that the model evaluates new, unseen images under the same conditions as during training. Normalization is crucial for maintaining consistent input feature scales during both training and testing phases.
"""

train_data = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range = 0.2, horizontal_flip = True)
test_data = ImageDataGenerator(rescale=1./255)

"""## Create Training Set"""

training_set = train_data.flow_from_directory('/content/drive/MyDrive/dataset/preprocessedTrainingData',
                                                 target_size = (128, 128),
                                                 batch_size = 10,
                                                 color_mode = 'grayscale',
                                                 class_mode = 'categorical')

testing_set = test_data.flow_from_directory('/content/drive/MyDrive/dataset/preprocessedTestingData',
                                                 target_size = (128, 128),
                                                 batch_size = 10,
                                                 color_mode = 'grayscale',
                                                 class_mode = 'categorical')

"""# Part 2: Building the CNN"""

classifier = tf.keras.models.Sequential()

classifier.add(tf.keras.layers.Conv2D(filters=32,
                                     kernel_size=3,
                                     padding="same",
                                     activation="relu",
                                     input_shape=[128, 128, 1]))

classifier.add(tf.keras.layers.MaxPool2D(pool_size=2,
                                         strides=2,
                                         padding='valid'))

classifier.add(tf.keras.layers.Conv2D(filters=32,
                                      kernel_size=3,
                                      padding="same",
                                      activation="relu"))

classifier.add(tf.keras.layers.MaxPool2D(pool_size=2,
                                         strides=2,
                                         padding='valid'))

classifier.add(tf.keras.layers.Flatten())

classifier.add(tf.keras.layers.Dense(units=128,
                                     activation='relu'))
classifier.add(tf.keras.layers.Dropout(0.40))
classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))
classifier.add(tf.keras.layers.Dropout(0.40))
classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))
classifier.add(tf.keras.layers.Dense(units=26, activation='softmax')) # softmax for more than 2

classifier.compile(optimizer = 'adam',
                   loss = 'categorical_crossentropy',
                   metrics = ['accuracy'])

classifier.summary()

classifier.fit(training_set,
                  epochs = 5,
                  validation_data = testing_set)

model_json = classifier.to_json()
with open("model_new.json", "w") as json_file:
    json_file.write(model_json)
print('Model Saved')
classifier.save_weights('model_new.h5')
print('Weights saved')

