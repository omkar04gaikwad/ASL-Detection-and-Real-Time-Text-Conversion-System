{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbebi43Hoojr",
        "outputId": "c783808f-3647-4491-9bee-6610d1fcd946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "pHVJ3h0EoyZE",
        "outputId": "f428b329-c60c-456f-e67c-5660c1c7aa95"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.15.0'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ED2MCXsg5z"
      },
      "source": [
        "#Part 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIDT3yM411Pt"
      },
      "source": [
        "##Image Data Augmentation with ImageDataGenerator\n",
        "**ImageDataGenerator** in Keras is a powerful utility that allows for the preprocessing and real-time augmentation of image data. This tool is essential for enhancing the diversity of the dataset without physically expanding it, thereby helping in the development of robust machine learning models. Below, we describe the transformations applied to both training and testing datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INTZqtbM2FFc"
      },
      "source": [
        "\n",
        "\n",
        "1.   Training Data Transformations\n",
        "\n",
        "\n",
        "- Rescaling (Normalization):\n",
        "\n",
        " * Purpose: Converts pixel values from a range of [0, 255] to [0, 1], ensuring that the neural network processes inputs that are normalized, leading to more stable and faster convergence.\n",
        "  * Computer Vision Concept: This is a basic form of data scaling in image processing, critical for balancing input feature scales.\n",
        "\n",
        "- Shear Transformation:\n",
        "\n",
        "  * Purpose: Randomly distorts the image along an axis, typically simulating a tilt, which helps the model learn to recognize objects in images that are not perfectly aligned with the axis.\n",
        "  * Computer Vision Concept: Shear is a type of affine transformation that slants the shape of an image, preserving lines but not distances or angles.\n",
        "\n",
        "- Zoom Transformation:\n",
        "\n",
        "  * Purpose: Randomly increases or decreases the size of the image, mimicking the effect of the camera moving closer or farther away. This teaches the model to recognize objects across different scales.\n",
        "  * Computer Vision Concept: Zoom is a scaling transformation that changes the effective resolution of the imaged objects.\n",
        "\n",
        "- Horizontal Flip:\n",
        "\n",
        "  * Purpose: Mirrors the image along the vertical axis, effectively doubling the number of different orientations the model sees during training.\n",
        "  * Computer Vision Concept: This is a reflection transformation, useful for datasets where object orientation is not a factor in classification accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgmQ6U3w3GXr"
      },
      "source": [
        "2.   Testing Data Transformations\n",
        "- Rescaling (Normalization):\n",
        "  * Purpose and Concept: Identical to the training data, ensures that the model evaluates new, unseen images under the same conditions as during training. Normalization is crucial for maintaining consistent input feature scales during both training and testing phases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVuESVdorwkk"
      },
      "outputs": [],
      "source": [
        "train_data = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "test_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqEgkuL93sA8"
      },
      "source": [
        "## Create Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN2Cgs6mryyV",
        "outputId": "766bc422-c37c-4b5d-b4dc-3998b9d99ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21605 images belonging to 26 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_data.flow_from_directory('/content/drive/MyDrive/dataset/preprocessedTrainingData',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 10,\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YPeg34_tdeu",
        "outputId": "cbb5bdd6-a084-4cfd-ecf0-1c9af8d689c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 5259 images belonging to 26 classes.\n"
          ]
        }
      ],
      "source": [
        "testing_set = test_data.flow_from_directory('/content/drive/MyDrive/dataset/preprocessedTestingData',\n",
        "                                                 target_size = (128, 128),\n",
        "                                                 batch_size = 10,\n",
        "                                                 color_mode = 'grayscale',\n",
        "                                                 class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnjpQczO5cDC"
      },
      "source": [
        "# Part 2: Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wET15DfU5JyK"
      },
      "outputs": [],
      "source": [
        "classifier = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8yub5ag5bFA"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"same\",\n",
        "                                     activation=\"relu\",\n",
        "                                     input_shape=[128, 128, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReghNOc752qu"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                         strides=2,\n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcrKAMDI55ay"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Conv2D(filters=32,\n",
        "                                      kernel_size=3,\n",
        "                                      padding=\"same\",\n",
        "                                      activation=\"relu\"))\n",
        "\n",
        "classifier.add(tf.keras.layers.MaxPool2D(pool_size=2,\n",
        "                                         strides=2,\n",
        "                                         padding='valid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbLbnRhF58za"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-4LW4CI5_Dz"
      },
      "outputs": [],
      "source": [
        "classifier.add(tf.keras.layers.Dense(units=128,\n",
        "                                     activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=96, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dropout(0.40))\n",
        "classifier.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
        "classifier.add(tf.keras.layers.Dense(units=26, activation='softmax')) # softmax for more than 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iryXC5-C6BF7"
      },
      "outputs": [],
      "source": [
        "classifier.compile(optimizer = 'adam',\n",
        "                   loss = 'categorical_crossentropy',\n",
        "                   metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hC8oMtK6Glq",
        "outputId": "b73e03b6-bf9f-4ede-8152-9ff1a1182580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 128, 128, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 64, 64, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 32, 32, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 96)                12384     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                6208      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 26)                1690      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4224282 (16.11 MB)\n",
            "Trainable params: 4224282 (16.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF5B7JD56KO9",
        "outputId": "e5640bc9-92ee-4eff-96d6-f84a1e101fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2161/2161 [==============================] - 576s 266ms/step - loss: 0.1040 - accuracy: 0.9674 - val_loss: 9.3331 - val_accuracy: 0.1852\n",
            "Epoch 2/5\n",
            "2161/2161 [==============================] - 579s 268ms/step - loss: 0.0868 - accuracy: 0.9729 - val_loss: 9.3226 - val_accuracy: 0.1947\n",
            "Epoch 3/5\n",
            "2161/2161 [==============================] - 550s 254ms/step - loss: 0.0706 - accuracy: 0.9785 - val_loss: 9.0114 - val_accuracy: 0.1510\n",
            "Epoch 4/5\n",
            "2161/2161 [==============================] - 553s 256ms/step - loss: 0.0652 - accuracy: 0.9797 - val_loss: 10.2375 - val_accuracy: 0.1597\n",
            "Epoch 5/5\n",
            "2161/2161 [==============================] - 581s 269ms/step - loss: 0.0621 - accuracy: 0.9817 - val_loss: 12.4722 - val_accuracy: 0.1649\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f1a95a092a0>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "classifier.fit(training_set,\n",
        "                  epochs = 5,\n",
        "                  validation_data = testing_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "bnMfDrsc6bjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa8b2b4-fdb2-4e7c-9820-f1119fa78889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n",
            "Weights saved\n"
          ]
        }
      ],
      "source": [
        "model_json = classifier.to_json()\n",
        "with open(\"model_new.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "print('Model Saved')\n",
        "classifier.save_weights('model_new.h5')\n",
        "print('Weights saved')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zob_x1dwWEgZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}